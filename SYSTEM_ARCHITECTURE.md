# ğŸ—ï¸ Complete RAG System Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     THU TUC HANH CHINH RAG SYSTEM                        â”‚
â”‚                   Vietnamese Administrative Procedures QA                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            USER INTERFACE                                â”‚
â”‚  â€¢ Interactive CLI                                                       â”‚
â”‚  â€¢ Batch Processing                                                      â”‚
â”‚  â€¢ API-ready architecture                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           QUERY INPUT                                    â”‚
â”‚  Example: "ÄÄƒng kÃ½ káº¿t hÃ´n cáº§n giáº¥y tá» gÃ¬?"                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PHASE 1-3: RETRIEVAL         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        STAGE 1: Query Enhancement                  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚ â€¢ Ollama qwen3:8b LLM                    â”‚     â”‚
        â”‚  â”‚ â€¢ Intent Detection (7 types)             â”‚     â”‚
        â”‚  â”‚ â€¢ Entity Extraction                      â”‚     â”‚
        â”‚  â”‚ â€¢ Query Variations (x3)                  â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     STAGE 2: Hierarchical Retrieval                â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚ Step 2.1: Parent Chunk Retrieval         â”‚     â”‚
        â”‚  â”‚   â€¢ Ollama BGE-M3 embeddings             â”‚     â”‚
        â”‚  â”‚   â€¢ Qdrant vector search                 â”‚     â”‚
        â”‚  â”‚   â€¢ Top-k=5 parent chunks                â”‚     â”‚
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
        â”‚  â”‚ Step 2.2: Child Chunk Retrieval          â”‚     â”‚
        â”‚  â”‚   â€¢ Per query variation                  â”‚     â”‚
        â”‚  â”‚   â€¢ Intent-based filtering               â”‚     â”‚
        â”‚  â”‚   â€¢ Parent-scoped search                 â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      STAGE 3: Multi-Query Fusion (RRF)             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚ â€¢ Reciprocal Rank Fusion                 â”‚     â”‚
        â”‚  â”‚ â€¢ Score: 1/(k + rank), k=60              â”‚     â”‚
        â”‚  â”‚ â€¢ Deduplication across variations        â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       STAGE 4: Re-ranking (Score Fusion)           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚ â€¢ Weighted fusion: 60% RRF + 40% Vector  â”‚     â”‚
        â”‚  â”‚ â€¢ Sort by final score                    â”‚     â”‚
        â”‚  â”‚ â€¢ Select top-k=3 chunks                  â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         STAGE 5: Context Assembly                  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚ â€¢ Parent + Child context blocks          â”‚     â”‚
        â”‚  â”‚ â€¢ Metadata enrichment                    â”‚     â”‚
        â”‚  â”‚ â€¢ Confidence calculation                 â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    PHASE 4: GENERATION         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    ANSWER GENERATION (Ollama qwen3:8b)             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚ Step 1: Extract Source Citations         â”‚     â”‚
        â”‚  â”‚   â€¢ chunk_id tracking                    â”‚     â”‚
        â”‚  â”‚   â€¢ Relevance scores                     â”‚     â”‚
        â”‚  â”‚   â€¢ Metadata preservation                â”‚     â”‚
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
        â”‚  â”‚ Step 2: Generate Structured Answer       â”‚     â”‚
        â”‚  â”‚   â€¢ Intent-specific JSON schema          â”‚     â”‚
        â”‚  â”‚   â€¢ Context-only extraction              â”‚     â”‚
        â”‚  â”‚   â€¢ Temperature=0.1 (precision)          â”‚     â”‚
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
        â”‚  â”‚ Step 3: Generate Natural Language        â”‚     â”‚
        â”‚  â”‚   â€¢ Structured data + context â†’ NL       â”‚     â”‚
        â”‚  â”‚   â€¢ Temperature=0.2 (fluency)            â”‚     â”‚
        â”‚  â”‚   â€¢ Vietnamese native quality            â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HYBRID OUTPUT                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 1. Natural Language Answer (Vietnamese)                       â”‚     â”‚
â”‚  â”‚    â€¢ User-friendly, conversational                            â”‚     â”‚
â”‚  â”‚    â€¢ Structured with bullet points                            â”‚     â”‚
â”‚  â”‚    â€¢ Important notes highlighted                              â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ 2. Structured JSON Data                                       â”‚     â”‚
â”‚  â”‚    â€¢ Intent-specific schema                                   â”‚     â”‚
â”‚  â”‚    â€¢ Machine-readable                                         â”‚     â”‚
â”‚  â”‚    â€¢ API integration ready                                    â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ 3. Source Citations                                           â”‚     â”‚
â”‚  â”‚    â€¢ chunk_id for each source                                 â”‚     â”‚
â”‚  â”‚    â€¢ Procedure name & code                                    â”‚     â”‚
â”‚  â”‚    â€¢ Relevance scores                                         â”‚     â”‚
â”‚  â”‚    â€¢ Content snippets                                         â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ 4. Metadata                                                   â”‚     â”‚
â”‚  â”‚    â€¢ Confidence score                                         â”‚     â”‚
â”‚  â”‚    â€¢ Intent classification                                    â”‚     â”‚
â”‚  â”‚    â€¢ Timestamp                                                â”‚     â”‚
â”‚  â”‚    â€¢ Query variations used                                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Architecture

### Data Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR DATABASE                      â”‚
â”‚                    (Qdrant Local)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Collection: thu_tuc_hanh_chinh               â”‚     â”‚
â”‚  â”‚ Dimension: 1024 (BGE-M3)                     â”‚     â”‚
â”‚  â”‚ Capacity: 1,084 chunks (target)              â”‚     â”‚
â”‚  â”‚   â€¢ 207 parent chunks                        â”‚     â”‚
â”‚  â”‚   â€¢ 877 child chunks                         â”‚     â”‚
â”‚  â”‚                                               â”‚     â”‚
â”‚  â”‚ Metadata Fields:                             â”‚     â”‚
â”‚  â”‚   â€¢ thu_tuc_id, chunk_id                     â”‚     â”‚
â”‚  â”‚   â€¢ chunk_tier (parent/child)                â”‚     â”‚
â”‚  â”‚   â€¢ chunk_type (7 types)                     â”‚     â”‚
â”‚  â”‚   â€¢ tÃªn_thá»§_tá»¥c, mÃ£_thá»§_tá»¥c, lÄ©nh_vá»±c       â”‚     â”‚
â”‚  â”‚   â€¢ parent_chunk_id (for children)           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OLLAMA MODELS                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 1. BGE-M3 (Embeddings)                       â”‚     â”‚
â”‚  â”‚    â€¢ Model: bge-m3                           â”‚     â”‚
â”‚  â”‚    â€¢ Dimension: 1024                         â”‚     â”‚
â”‚  â”‚    â€¢ Normalized vectors                      â”‚     â”‚
â”‚  â”‚    â€¢ Multilingual support                    â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ 2. Qwen3:8B (LLM)                            â”‚     â”‚
â”‚  â”‚    â€¢ Query Enhancement                       â”‚     â”‚
â”‚  â”‚    â€¢ Answer Generation                       â”‚     â”‚
â”‚  â”‚    â€¢ Vietnamese-optimized                    â”‚     â”‚
â”‚  â”‚    â€¢ Context window: ~32k tokens             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  Server: http://localhost:11434                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSING STAGES                          â”‚
â”‚                                                               â”‚
â”‚  Input Query                                                  â”‚
â”‚       â†“                                                       â”‚
â”‚  [Query Enhancer]      â†’ Intent + Entities + Variations      â”‚
â”‚       â†“                                                       â”‚
â”‚  [Embedder]            â†’ Query vectors (1024-dim)            â”‚
â”‚       â†“                                                       â”‚
â”‚  [Vector Store]        â†’ Parent chunks (cosine similarity)   â”‚
â”‚       â†“                                                       â”‚
â”‚  [Vector Store]        â†’ Child chunks (filtered by parent)   â”‚
â”‚       â†“                                                       â”‚
â”‚  [RRF Fusion]          â†’ Deduplicated + ranked results       â”‚
â”‚       â†“                                                       â”‚
â”‚  [Score Fusion]        â†’ Top-k re-ranked chunks              â”‚
â”‚       â†“                                                       â”‚
â”‚  [Context Assembly]    â†’ Structured context blocks           â”‚
â”‚       â†“                                                       â”‚
â”‚  [Answer Generator]    â†’ JSON + Natural Language             â”‚
â”‚       â†“                                                       â”‚
â”‚  Output (Hybrid)                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Intent Classification System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTENT TYPES (7)                             â”‚
â”‚                                                                 â”‚
â”‚  1. documents      â†’ Giáº¥y tá», há»“ sÆ¡                            â”‚
â”‚     Schema: ho_so_bao_gom, so_ban, ghi_chu                     â”‚
â”‚                                                                 â”‚
â”‚  2. requirements   â†’ Äiá»u kiá»‡n, yÃªu cáº§u                        â”‚
â”‚     Schema: doi_tuong, dieu_kien, yeu_cau                      â”‚
â”‚                                                                 â”‚
â”‚  3. process        â†’ Quy trÃ¬nh, cÃ¡c bÆ°á»›c                       â”‚
â”‚     Schema: cac_buoc[], ghi_chu                                â”‚
â”‚                                                                 â”‚
â”‚  4. legal          â†’ CÄƒn cá»© phÃ¡p lÃ½                            â”‚
â”‚     Schema: can_cu_phap_ly[], ghi_chu                          â”‚
â”‚                                                                 â”‚
â”‚  5. timeline       â†’ Thá»i gian, thá»i háº¡n                       â”‚
â”‚     Schema: thoi_han_giai_quyet, thoi_gian_tiep_nhan           â”‚
â”‚                                                                 â”‚
â”‚  6. fees           â†’ PhÃ­, lá»‡ phÃ­                               â”‚
â”‚     Schema: le_phi, phi_khac, ghi_chu                          â”‚
â”‚                                                                 â”‚
â”‚  7. overview       â†’ Tá»•ng quan                                 â”‚
â”‚     Schema: ten_thu_tuc, ma_thu_tuc, linh_vuc, trich_yeu       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TECHNOLOGY STACK                      â”‚
â”‚                                                          â”‚
â”‚  Language:        Python 3.10+                          â”‚
â”‚  Vector DB:       Qdrant (local storage)                â”‚
â”‚  LLM Runtime:     Ollama (localhost:11434)              â”‚
â”‚  Embedding Model: BGE-M3 (1024-dim)                     â”‚
â”‚  LLM Model:       Qwen3:8B                              â”‚
â”‚  Dependencies:                                           â”‚
â”‚    â€¢ qdrant-client                                      â”‚
â”‚    â€¢ requests (Ollama API)                              â”‚
â”‚    â€¢ numpy                                              â”‚
â”‚    â€¢ dataclasses                                        â”‚
â”‚    â€¢ json, pathlib, datetime                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Organization

```
thu_tuc_rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extraction/              # Phase 1: Data Extraction
â”‚   â”‚   â”œâ”€â”€ extract_documents.py
â”‚   â”‚   â””â”€â”€ data_validator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ chunking/                # Phase 2: Hierarchical Chunking
â”‚   â”‚   â”œâ”€â”€ hierarchical_chunker.py
â”‚   â”‚   â””â”€â”€ test_chunker.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/               # Phase 3: Retrieval Pipeline
â”‚   â”‚   â”œâ”€â”€ embedding_model.py         # BGE-M3 wrapper
â”‚   â”‚   â”œâ”€â”€ vector_store.py            # Qdrant interface
â”‚   â”‚   â”œâ”€â”€ query_enhancer.py          # Query enhancement
â”‚   â”‚   â”œâ”€â”€ retrieval_pipeline.py      # 5-stage retrieval
â”‚   â”‚   â””â”€â”€ qdrant_storage/            # Vector DB storage
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/              # Phase 4: Answer Generation
â”‚   â”‚   â””â”€â”€ answer_generator.py        # LLM answer synthesis
â”‚   â”‚
â”‚   â””â”€â”€ pipeline/                # Complete Integration
â”‚       â”œâ”€â”€ rag_pipeline.py            # End-to-end RAG
â”‚       â””â”€â”€ test_with_mock_data.py     # Testing
â”‚
â”œâ”€â”€ PHASE_4_SUMMARY.md          # Phase 4 documentation
â””â”€â”€ SYSTEM_ARCHITECTURE.md      # This file
```

---

## Performance Characteristics

### Latency Breakdown

```
Total Query Processing Time: 50-180 seconds

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Query Enhancement          5-15s      â”‚
â”‚   â€¢ Intent detection: 2-5s                     â”‚
â”‚   â€¢ Entity extraction: 2-5s                    â”‚
â”‚   â€¢ Query variations: 1-5s                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stage 2: Hierarchical Retrieval     5-10s      â”‚
â”‚   â€¢ Parent embedding: 1-2s                     â”‚
â”‚   â€¢ Parent search: 1-2s                        â”‚
â”‚   â€¢ Child embeddings (3x): 3-6s                â”‚
â”‚   â€¢ Child searches (3x): 1-2s                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stage 3: RRF Fusion                 <1s        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stage 4: Re-ranking                 <1s        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stage 5: Context Assembly           <1s        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Answer Gen: Structured JSON         30-120s    â”‚
â”‚ Answer Gen: Natural Language        20-60s     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Optimization Opportunities:
â€¢ Batch query variations (parallel)
â€¢ Cache embeddings for common queries
â€¢ Use cloud LLM API (faster inference)
â€¢ Implement streaming output
```

### Resource Usage

```
Memory:
â€¢ Qdrant: ~100-500MB (1k chunks)
â€¢ Ollama BGE-M3: ~2GB
â€¢ Ollama Qwen3:8B: ~5GB
â€¢ Python process: ~200MB
Total: ~8GB RAM minimum

Disk:
â€¢ Vector DB: ~50MB (1k chunks)
â€¢ Models: ~8GB (BGE-M3 + Qwen3)
Total: ~8.5GB disk space

CPU/GPU:
â€¢ GPU recommended for Ollama
â€¢ CPU fallback supported (slower)
```

---

## Data Flow Example

### Example Query: "ÄÄƒng kÃ½ káº¿t hÃ´n cáº§n giáº¥y tá» gÃ¬?"

```
1. INPUT
   â”œâ”€ Original: "ÄÄƒng kÃ½ káº¿t hÃ´n cáº§n giáº¥y tá» gÃ¬?"

2. QUERY ENHANCEMENT
   â”œâ”€ Intent: documents
   â”œâ”€ Entities: {thu_tuc_name: "ÄÄƒng kÃ½ káº¿t hÃ´n", linh_vuc: "há»™ tá»‹ch"}
   â”œâ”€ Variations:
   â”‚   â”œâ”€ "ÄÄƒng kÃ½ káº¿t hÃ´n cáº§n giáº¥y tá» gÃ¬?"
   â”‚   â”œâ”€ "Há»“ sÆ¡ Ä‘Äƒng kÃ½ káº¿t hÃ´n gá»“m nhá»¯ng gÃ¬?"
   â”‚   â””â”€ "Giáº¥y tá» cáº§n thiáº¿t Ä‘á»ƒ Ä‘Äƒng kÃ½ káº¿t hÃ´n?"

3. RETRIEVAL (5 stages)
   â”œâ”€ Parent chunks: 2 retrieved (score: 0.85, 0.78)
   â”œâ”€ Child chunks: 15 retrieved, filtered to 8
   â”œâ”€ RRF fusion: 8 unique chunks
   â”œâ”€ Re-ranked: Top 3 selected (final scores: 0.8954, 0.7845, 0.7234)
   â”œâ”€ Context: 3 blocks assembled

4. GENERATION
   â”œâ”€ Source extraction: 3 sources with chunk_ids
   â”œâ”€ Structured JSON:
   â”‚   {
   â”‚     "ho_so_bao_gom": ["CMND/CCCD", "Giáº¥y xÃ¡c nháº­n", ...],
   â”‚     "so_ban": {"CMND/CCCD": "02", ...},
   â”‚     "ghi_chu": "..."
   â”‚   }
   â”œâ”€ Natural language: 1500 chars Vietnamese

5. OUTPUT
   â”œâ”€ Confidence: 85%
   â”œâ”€ Intent: documents
   â”œâ”€ Sources: 3 citations
   â”œâ”€ Format: JSON + NL hybrid
   â””â”€ Timestamp: 2025-12-29T08:06:46
```

---

## Hallucination Prevention Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          HALLUCINATION PREVENTION LAYERS             â”‚
â”‚                                                       â”‚
â”‚  Layer 1: Strict System Prompts                     â”‚
â”‚    â€¢ "CHá»ˆ tráº£ lá»i dá»±a trÃªn CONTEXT"                 â”‚
â”‚    â€¢ "KHÃ”NG bá»‹a Ä‘áº·t thÃ´ng tin"                      â”‚
â”‚    â€¢ Explicit fallback instructions                  â”‚
â”‚                                                       â”‚
â”‚  Layer 2: Low Temperature Sampling                   â”‚
â”‚    â€¢ Structured: temperature=0.1                     â”‚
â”‚    â€¢ Natural Language: temperature=0.2               â”‚
â”‚    â€¢ Reduces creative hallucination                  â”‚
â”‚                                                       â”‚
â”‚  Layer 3: Source Citation Requirement                â”‚
â”‚    â€¢ Every answer includes chunk_ids                 â”‚
â”‚    â€¢ Traceable to original documents                 â”‚
â”‚    â€¢ Verifiable content snippets                     â”‚
â”‚                                                       â”‚
â”‚  Layer 4: Context-Only Validation (Future)           â”‚
â”‚    â€¢ NLI contradiction detection                     â”‚
â”‚    â€¢ Cross-reference checking                        â”‚
â”‚    â€¢ Self-consistency voting                         â”‚
â”‚    â€¢ Chain-of-verification                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Scaling Considerations

### Current Capacity
- **Documents:** 207 procedures
- **Chunks:** 1,084 total (207 parent + 877 child)
- **Queries:** ~10-20 per hour (local Ollama limit)

### Scaling to 10,000+ Procedures

```
1. Vector Database
   âœ“ Qdrant scales to billions of vectors
   âœ“ Current: Local storage
   âœ“ Production: Qdrant Cloud or self-hosted cluster

2. LLM Inference
   âœ— Ollama limited to local GPU
   âœ“ Alternative: OpenAI API, Anthropic Claude, Azure OpenAI
   âœ“ Benefit: 10-100x faster, higher concurrency

3. Caching Layer
   + Redis for query result caching
   + Embedding cache for common queries
   + Response cache with TTL

4. Load Balancing
   + Multiple Ollama instances
   + Queue-based processing
   + Async/parallel retrieval
```

---

## Security & Privacy

```
Current Setup (Local)
âœ“ All data stored locally
âœ“ No external API calls (except Ollama localhost)
âœ“ No data leakage
âœ“ GDPR/privacy compliant

Production Considerations
â€¢ Authentication & authorization
â€¢ Rate limiting
â€¢ Input sanitization
â€¢ Output filtering (PII redaction)
â€¢ Audit logging
â€¢ Encryption at rest & in transit
```

---

## Future Enhancements

### Phase 5: Validation & Optimization
1. NLI hallucination detection
2. Self-consistency validation
3. Chain-of-verification
4. Response caching

### Phase 6: Evaluation & Testing
1. 50-100 test case dataset
2. Automated accuracy metrics
3. A/B testing framework
4. User feedback loop

### Phase 7: Production Features
1. REST API with FastAPI
2. Web UI (React/Vue)
3. Mobile app integration
4. Multi-language support
5. Real-time updates
6. Analytics dashboard

---

**Document Version:** 1.0
**Last Updated:** 2025-12-29
**Status:** Production-ready architecture
**Next:** Phase 5 implementation
