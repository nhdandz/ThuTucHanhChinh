#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ validate d·ªØ li·ªáu ƒë√£ extract t·ª´ file .doc
ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu tr∆∞·ªõc khi chunking
"""

import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')


class DataValidator:
    """Validator cho d·ªØ li·ªáu th·ªß t·ª•c h√†nh ch√≠nh"""

    # C√°c tr∆∞·ªùng b·∫Øt bu·ªôc ph·∫£i c√≥
    REQUIRED_METADATA_FIELDS = ["ma_thu_tuc", "ten_thu_tuc", "linh_vuc"]
    REQUIRED_CONTENT_FIELDS = ["doi_tuong_thuc_hien", "co_quan_thuc_hien"]

    def __init__(self):
        self.validation_results = []
        self.issues = []

    def validate_json_structure(self, data: Dict, file_id: str) -> bool:
        """Ki·ªÉm tra c·∫•u tr√∫c JSON c∆° b·∫£n"""
        issues = []

        # Check required top-level keys
        required_keys = ["thu_tuc_id", "metadata", "content", "tables"]
        for key in required_keys:
            if key not in data:
                issues.append(f"Missing key: {key}")

        if issues:
            self.issues.append({"file_id": file_id, "type": "structure", "issues": issues})
            return False

        return True

    def validate_metadata(self, data: Dict, file_id: str) -> Tuple[bool, List[str]]:
        """Ki·ªÉm tra metadata fields"""
        issues = []
        metadata = data.get("metadata", {})

        # Check required fields
        for field in self.REQUIRED_METADATA_FIELDS:
            if not metadata.get(field) or metadata.get(field).strip() == "":
                issues.append(f"Empty required metadata: {field}")

        # Check field lengths
        if metadata.get("ten_thu_tuc"):
            length = len(metadata["ten_thu_tuc"])
            if length < 10:
                issues.append(f"T√™n th·ªß t·ª•c qu√° ng·∫Øn ({length} chars)")
            elif length > 500:
                issues.append(f"T√™n th·ªß t·ª•c qu√° d√†i ({length} chars)")

        if issues:
            self.issues.append({"file_id": file_id, "type": "metadata", "issues": issues})
            return False, issues

        return True, []

    def validate_content(self, data: Dict, file_id: str) -> Tuple[bool, List[str]]:
        """Ki·ªÉm tra content fields"""
        issues = []
        content = data.get("content", {})

        # Check required fields
        for field in self.REQUIRED_CONTENT_FIELDS:
            if not content.get(field) or content.get(field).strip() == "":
                issues.append(f"Empty required content: {field}")

        # Check important fields c√≥ d·ªØ li·ªáu
        important_fields = [
            "yeu_cau_dieu_kien_thuc_hien",
            "trinh_tu_thuc_hien",
            "cach_thuc_thuc_hien"
        ]

        empty_important = []
        for field in important_fields:
            if not content.get(field) or content.get(field).strip() == "":
                empty_important.append(field)

        if len(empty_important) >= 2:
            issues.append(f"Nhi·ªÅu tr∆∞·ªùng quan tr·ªçng tr·ªëng: {', '.join(empty_important)}")

        if issues:
            self.issues.append({"file_id": file_id, "type": "content", "issues": issues})
            return False, issues

        return True, []

    def validate_tables(self, data: Dict, file_id: str) -> Tuple[bool, List[str]]:
        """Ki·ªÉm tra d·ªØ li·ªáu b·∫£ng"""
        issues = []
        tables = data.get("tables", {})

        # Check th√†nh ph·∫ßn h·ªì s∆°
        thanh_phan_ho_so = tables.get("thanh_phan_ho_so", [])
        if not thanh_phan_ho_so or len(thanh_phan_ho_so) == 0:
            issues.append("Kh√¥ng c√≥ th√†nh ph·∫ßn h·ªì s∆°")
        else:
            # Check structure c·ªßa t·ª´ng item
            for i, item in enumerate(thanh_phan_ho_so):
                if not isinstance(item, dict):
                    issues.append(f"Th√†nh ph·∫ßn h·ªì s∆° item {i} kh√¥ng ph·∫£i dict")
                elif not item.get("ten_giay_to"):
                    issues.append(f"Th√†nh ph·∫ßn h·ªì s∆° item {i} thi·∫øu t√™n gi·∫•y t·ªù")

        # Check cƒÉn c·ª© ph√°p l√Ω
        can_cu_phap_ly = tables.get("can_cu_phap_ly", [])
        if not can_cu_phap_ly or len(can_cu_phap_ly) == 0:
            issues.append("Kh√¥ng c√≥ cƒÉn c·ª© ph√°p l√Ω")

        # Warning n·∫øu kh√¥ng c√≥ h√¨nh th·ª©c n·ªôp (kh√¥ng ph·∫£i l·ªói critical)
        hinh_thuc_nop = tables.get("hinh_thuc_nop", [])
        if not hinh_thuc_nop or len(hinh_thuc_nop) == 0:
            # Kh√¥ng th√™m v√†o issues v√¨ m·ªôt s·ªë th·ªß t·ª•c c√≥ th·ªÉ kh√¥ng c√≥
            pass

        if issues:
            self.issues.append({"file_id": file_id, "type": "tables", "issues": issues})
            return False, issues

        return True, []

    def validate_file(self, file_path: Path) -> Dict:
        """Validate m·ªôt file JSON"""
        file_id = file_path.stem

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            result = {
                "file_id": file_id,
                "file_path": str(file_path),
                "valid": True,
                "issues": []
            }

            # Validate structure
            if not self.validate_json_structure(data, file_id):
                result["valid"] = False

            # Validate metadata
            valid_metadata, metadata_issues = self.validate_metadata(data, file_id)
            if not valid_metadata:
                result["valid"] = False
                result["issues"].extend(metadata_issues)

            # Validate content
            valid_content, content_issues = self.validate_content(data, file_id)
            if not valid_content:
                result["valid"] = False
                result["issues"].extend(content_issues)

            # Validate tables
            valid_tables, table_issues = self.validate_tables(data, file_id)
            if not valid_tables:
                result["valid"] = False
                result["issues"].extend(table_issues)

            return result

        except json.JSONDecodeError as e:
            return {
                "file_id": file_id,
                "file_path": str(file_path),
                "valid": False,
                "issues": [f"JSON decode error: {str(e)}"]
            }
        except Exception as e:
            return {
                "file_id": file_id,
                "file_path": str(file_path),
                "valid": False,
                "issues": [f"Error: {str(e)}"]
            }

    def validate_all(self, json_dir: Path) -> Dict:
        """Validate t·∫•t c·∫£ files trong directory"""
        json_files = list(json_dir.glob("*.json"))

        print(f"üîç B·∫Øt ƒë·∫ßu validate {len(json_files)} files...")
        print()

        valid_count = 0
        invalid_count = 0

        for i, file_path in enumerate(json_files, 1):
            print(f"\r‚è≥ Validating: {i}/{len(json_files)}", end='', flush=True)

            result = self.validate_file(file_path)
            self.validation_results.append(result)

            if result["valid"]:
                valid_count += 1
            else:
                invalid_count += 1

        print("\n")

        # T·∫°o summary
        summary = {
            "total_files": len(json_files),
            "valid_files": valid_count,
            "invalid_files": invalid_count,
            "validation_rate": valid_count / len(json_files) * 100 if json_files else 0
        }

        return summary

    def generate_report(self, output_path: Path):
        """T·∫°o b√°o c√°o validation chi ti·∫øt"""
        print("=" * 80)
        print("K·∫æT QU·∫¢ VALIDATION")
        print("=" * 80)
        print()

        # T·ªïng quan
        valid_count = sum(1 for r in self.validation_results if r["valid"])
        total_count = len(self.validation_results)

        print(f"üìä T·ªïng s·ªë files: {total_count}")
        print(f"‚úÖ Files h·ª£p l·ªá: {valid_count} ({valid_count/total_count*100:.1f}%)")
        print(f"‚ùå Files c√≥ v·∫•n ƒë·ªÅ: {total_count - valid_count} ({(total_count-valid_count)/total_count*100:.1f}%)")
        print()

        # Files c√≥ v·∫•n ƒë·ªÅ
        invalid_files = [r for r in self.validation_results if not r["valid"]]

        if invalid_files:
            print("=" * 80)
            print("FILES C√ì V·∫§N ƒê·ªÄ")
            print("=" * 80)

            # Nh√≥m theo lo·∫°i v·∫•n ƒë·ªÅ
            issue_types = {}
            for r in invalid_files:
                for issue in r["issues"]:
                    issue_type = issue.split(":")[0]
                    if issue_type not in issue_types:
                        issue_types[issue_type] = []
                    issue_types[issue_type].append(r["file_id"])

            for issue_type, file_ids in sorted(issue_types.items()):
                print(f"\nüìå {issue_type}: {len(file_ids)} files")
                for fid in file_ids[:5]:  # Hi·ªÉn th·ªã max 5
                    print(f"   - {fid}")
                if len(file_ids) > 5:
                    print(f"   ... v√† {len(file_ids) - 5} files kh√°c")

        # L∆∞u detailed report
        print()
        print(f"üíæ L∆∞u b√°o c√°o chi ti·∫øt...")

        # Save validation results to JSON
        report_json = output_path / "validation_report.json"
        with open(report_json, 'w', encoding='utf-8') as f:
            json.dump({
                "summary": {
                    "total_files": total_count,
                    "valid_files": valid_count,
                    "invalid_files": total_count - valid_count
                },
                "details": self.validation_results,
                "issues": self.issues
            }, f, ensure_ascii=False, indent=2)

        print(f"   ‚úì JSON report: {report_json}")

        # Save to CSV for easy viewing
        df = pd.DataFrame(self.validation_results)
        report_csv = output_path / "validation_report.csv"
        df.to_csv(report_csv, index=False, encoding='utf-8-sig')
        print(f"   ‚úì CSV report: {report_csv}")

        print()
        print("=" * 80)


def main():
    """Main function"""
    # T√¨m ƒë∆∞·ªùng d·∫´n
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    data_dir = project_root / "data"
    extracted_dir = data_dir / "extracted"

    if not extracted_dir.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c extracted: {extracted_dir}")
        print("   H√£y ch·∫°y extract_documents.py tr∆∞·ªõc!")
        return

    # Create validator v√† run
    validator = DataValidator()
    summary = validator.validate_all(extracted_dir)

    # Generate report
    validator.generate_report(data_dir)

    # Return summary
    return summary


if __name__ == "__main__":
    main()
