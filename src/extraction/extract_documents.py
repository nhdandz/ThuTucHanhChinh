#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ extract th√¥ng tin t·ª´ 207 file .doc th·ªß t·ª•c h√†nh ch√≠nh
Output: JSON files v·ªõi c·∫•u tr√∫c chu·∫©n h√≥a
"""

import sys
import os
import json
from pathlib import Path
from docx import Document
import glob
from typing import Dict, List, Optional
import re

# ƒê·∫£m b·∫£o output UTF-8
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# Danh s√°ch 20 tr∆∞·ªùng quan tr·ªçng
FIELDS_TO_TRACK = [
    "M√£ th·ªß t·ª•c",
    "S·ªë quy·∫øt ƒë·ªãnh",
    "T√™n th·ªß t·ª•c",
    "C·∫•p th·ª±c hi·ªán",
    "Lo·∫°i th·ªß t·ª•c",
    "Lƒ©nh v·ª±c",
    "Tr√¨nh t·ª± th·ª±c hi·ªán",
    "C√°ch th·ª©c th·ª±c hi·ªán",
    "Th√†nh ph·∫ßn h·ªì s∆°",
    "ƒê·ªëi t∆∞·ª£ng th·ª±c hi·ªán",
    "C∆° quan th·ª±c hi·ªán",
    "C∆° quan c√≥ th·∫©m quy·ªÅn",
    "ƒê·ªãa ch·ªâ ti·∫øp nh·∫≠n HS",
    "C∆° quan ƒë∆∞·ª£c ·ªßy quy·ªÅn",
    "C∆° quan ph·ªëi h·ª£p",
    "K·∫øt qu·∫£ th·ª±c hi·ªán",
    "CƒÉn c·ª© ph√°p l√Ω",
    "Y√™u c·∫ßu, ƒëi·ªÅu ki·ªán th·ª±c hi·ªán",
    "T·ª´ kh√≥a",
    "M√¥ t·∫£"
]


def extract_field_value(paragraphs: List, field_name: str) -> str:
    """
    Tr√≠ch xu·∫•t gi√° tr·ªã c·ªßa m·ªôt tr∆∞·ªùng t·ª´ danh s√°ch paragraphs
    """
    field_value = ""
    capturing = False

    for para in paragraphs:
        text = para.text.strip()

        # B·∫Øt ƒë·∫ßu capture khi t√¨m th·∫•y t√™n tr∆∞·ªùng
        if text.startswith(field_name + ":"):
            # L·∫•y ph·∫ßn sau d·∫•u ':'
            field_value = text[len(field_name) + 1:].strip()
            capturing = True
            continue

        # N·∫øu ƒëang capture v√† g·∫∑p tr∆∞·ªùng ti·∫øp theo, d·ª´ng l·∫°i
        if capturing:
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† m·ªôt tr∆∞·ªùng m·ªõi kh√¥ng
            is_new_field = any(text.startswith(f + ":") for f in FIELDS_TO_TRACK)
            # Ho·∫∑c l√† d√≤ng "B∆∞·ªõc X:"
            if is_new_field or text.startswith("B∆∞·ªõc "):
                break
            # N·∫øu kh√¥ng ph·∫£i tr∆∞·ªùng m·ªõi, th√™m v√†o gi√° tr·ªã
            if text:
                field_value += " " + text

    return field_value.strip()


def extract_table_data(doc: Document) -> Dict[str, List]:
    """
    Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c b·∫£ng trong document
    T·ª± ƒë·ªông nh·∫≠n bi·∫øt b·∫£ng d·ª±a v√†o header
    """
    table_data = {
        'hinh_thuc_nop': [],
        'thoi_han_giai_quyet': [],
        'phi_le_phi': [],
        'thanh_phan_ho_so': [],
        'can_cu_phap_ly': []
    }

    if len(doc.tables) < 1:
        return table_data

    # Duy·ªát qua t·∫•t c·∫£ c√°c b·∫£ng
    for table in doc.tables:
        if len(table.rows) < 1:
            continue

        # ƒê·ªçc header (h√†ng ƒë·∫ßu ti√™n)
        header_cells = [cell.text.strip().lower() for cell in table.rows[0].cells]

        # Nh·∫≠n di·ªán B·∫£ng 1: H√¨nh th·ª©c n·ªôp, Th·ªùi h·∫°n, Ph√≠ l·ªá ph√≠
        if any('h√¨nh th·ª©c' in h for h in header_cells) and any('th·ªùi h·∫°n' in h for h in header_cells):
            for i, row in enumerate(table.rows):
                if i == 0:  # B·ªè qua header
                    continue
                cells = [cell.text.strip() for cell in row.cells]
                if len(cells) >= 3 and cells[0]:
                    table_data['hinh_thuc_nop'].append(cells[0])
                    table_data['thoi_han_giai_quyet'].append(cells[1])
                    table_data['phi_le_phi'].append(cells[2])

        # Nh·∫≠n di·ªán B·∫£ng 2: Th√†nh ph·∫ßn h·ªì s∆°
        elif any('t√™n gi·∫•y t·ªù' in h for h in header_cells) or any('gi·∫•y t·ªù' in h for h in header_cells):
            for i, row in enumerate(table.rows):
                if i == 0:
                    continue
                cells = [cell.text.strip() for cell in row.cells]
                if len(cells) >= 1 and cells[0]:
                    # L·∫•y th√™m s·ªë l∆∞·ª£ng v√† ghi ch√∫ n·∫øu c√≥
                    ten_giay_to = cells[0]
                    so_luong = cells[1] if len(cells) > 1 else ""
                    ghi_chu = cells[2] if len(cells) > 2 else ""

                    table_data['thanh_phan_ho_so'].append({
                        "ten_giay_to": ten_giay_to,
                        "so_luong": so_luong,
                        "ghi_chu": ghi_chu
                    })

        # Nh·∫≠n di·ªán B·∫£ng 3: CƒÉn c·ª© ph√°p l√Ω
        elif any('tr√≠ch y·∫øu' in h for h in header_cells) or any('s·ªë k√Ω hi·ªáu' in h for h in header_cells):
            for i, row in enumerate(table.rows):
                if i == 0:
                    continue
                cells = [cell.text.strip() for cell in row.cells]

                # T√¨m c·ªôt "Tr√≠ch y·∫øu"
                trich_yeu_col = -1
                so_ky_hieu_col = -1

                for idx, h in enumerate(header_cells):
                    if 'tr√≠ch y·∫øu' in h:
                        trich_yeu_col = idx
                    if 's·ªë' in h and 'k√Ω hi·ªáu' in h:
                        so_ky_hieu_col = idx

                if len(cells) > max(trich_yeu_col, so_ky_hieu_col):
                    so_ky_hieu = cells[so_ky_hieu_col] if so_ky_hieu_col >= 0 else cells[0]
                    trich_yeu = cells[trich_yeu_col] if trich_yeu_col >= 0 else cells[1] if len(cells) > 1 else ""

                    if so_ky_hieu or trich_yeu:
                        table_data['can_cu_phap_ly'].append({
                            "so_ky_hieu": so_ky_hieu,
                            "trich_yeu": trich_yeu
                        })

    return table_data


def extract_thu_tuc_id_from_filename(filename: str) -> str:
    """
    Extract ID t·ª´ t√™n file: ChiTietTTHC_1.013124.doc -> 1.013124
    """
    match = re.search(r'_(\d+\.\d+)\.doc', filename)
    if match:
        return match.group(1)
    return filename.replace('ChiTietTTHC_', '').replace('.doc', '')


def analyze_doc_file(file_path: str) -> Optional[Dict]:
    """
    Ph√¢n t√≠ch m·ªôt file .doc v√† tr·∫£ v·ªÅ c·∫•u tr√∫c JSON chu·∫©n
    """
    try:
        doc = Document(file_path)
        paragraphs = doc.paragraphs
        filename = os.path.basename(file_path)

        # Extract ID t·ª´ filename
        thu_tuc_id = extract_thu_tuc_id_from_filename(filename)

        # Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ b·∫£ng
        table_data = extract_table_data(doc)

        # T·∫°o metadata
        metadata = {}
        for field in ["M√£ th·ªß t·ª•c", "T√™n th·ªß t·ª•c", "S·ªë quy·∫øt ƒë·ªãnh",
                     "C·∫•p th·ª±c hi·ªán", "Lo·∫°i th·ªß t·ª•c", "Lƒ©nh v·ª±c"]:
            value = extract_field_value(paragraphs, field)
            # Normalize field name cho JSON key
            key = field.lower().replace(" ", "_").replace(",", "")
            metadata[key] = value

        # T·∫°o content
        content = {}
        for field in ["Tr√¨nh t·ª± th·ª±c hi·ªán", "C√°ch th·ª©c th·ª±c hi·ªán",
                     "ƒê·ªëi t∆∞·ª£ng th·ª±c hi·ªán", "C∆° quan th·ª±c hi·ªán",
                     "C∆° quan c√≥ th·∫©m quy·ªÅn", "C∆° quan ph·ªëi h·ª£p",
                     "ƒê·ªãa ch·ªâ ti·∫øp nh·∫≠n HS", "K·∫øt qu·∫£ th·ª±c hi·ªán",
                     "Y√™u c·∫ßu, ƒëi·ªÅu ki·ªán th·ª±c hi·ªán"]:
            value = extract_field_value(paragraphs, field)
            key = field.lower().replace(" ", "_").replace(",", "")
            content[key] = value

        # T·∫°o JSON structure
        result = {
            "thu_tuc_id": thu_tuc_id,
            "source_file": filename,
            "metadata": metadata,
            "content": content,
            "tables": {
                "hinh_thuc_nop": [
                    {
                        "hinh_thuc": table_data['hinh_thuc_nop'][i] if i < len(table_data['hinh_thuc_nop']) else "",
                        "thoi_han_giai_quyet": table_data['thoi_han_giai_quyet'][i] if i < len(table_data['thoi_han_giai_quyet']) else "",
                        "phi_le_phi": table_data['phi_le_phi'][i] if i < len(table_data['phi_le_phi']) else ""
                    }
                    for i in range(max(len(table_data['hinh_thuc_nop']),
                                      len(table_data['thoi_han_giai_quyet']),
                                      len(table_data['phi_le_phi'])))
                ] if table_data['hinh_thuc_nop'] or table_data['thoi_han_giai_quyet'] or table_data['phi_le_phi'] else [],
                "thanh_phan_ho_so": table_data['thanh_phan_ho_so'],
                "can_cu_phap_ly": table_data['can_cu_phap_ly']
            }
        }

        return result

    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file {file_path}: {str(e)}")
        return None


def main():
    """
    H√†m ch√≠nh ƒë·ªÉ extract t·∫•t c·∫£ c√°c file
    """
    print("=" * 80)
    print("EXTRACT D·ªÆ LI·ªÜU T·ª™ 207 FILE TH·ª¶ T·ª§C H√ÄNH CH√çNH")
    print("=" * 80)
    print()

    # T√¨m ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a file .doc
    # Script n√†y n·∫±m trong thu_tuc_rag/src/extraction/
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    data_dir = project_root / "data"

    # T√¨m file .doc ·ªü th∆∞ m·ª•c g·ªëc (n∆°i c√≥ 207 files)
    root_dir = project_root.parent
    file_pattern = str(root_dir / "ChiTietTTHC_*.doc")

    files = glob.glob(file_pattern)

    # Lo·∫°i b·ªè c√°c file t·∫°m
    files = [f for f in files if not os.path.basename(f).startswith('~$')]

    print(f"üìÅ T√¨m th·∫•y {len(files)} file th·ªß t·ª•c h√†nh ch√≠nh")
    print(f"üìÇ Output directory: {data_dir / 'extracted'}")
    print()

    if len(files) == 0:
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file n√†o!")
        print(f"   ƒê√£ t√¨m ·ªü: {file_pattern}")
        return

    # T·∫°o th∆∞ m·ª•c output
    output_dir = data_dir / "extracted"
    output_dir.mkdir(parents=True, exist_ok=True)

    # Extract t·∫•t c·∫£ c√°c file
    success_count = 0
    failed_files = []

    for i, file_path in enumerate(files, 1):
        filename = os.path.basename(file_path)
        print(f"\r‚è≥ ƒêang x·ª≠ l√Ω: {i}/{len(files)} - {filename}", end='', flush=True)

        data = analyze_doc_file(file_path)

        if data:
            # L∆∞u ra file JSON
            thu_tuc_id = data['thu_tuc_id']
            output_file = output_dir / f"{thu_tuc_id}.json"

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            success_count += 1
        else:
            failed_files.append(filename)

    print("\n\n" + "=" * 80)
    print("K·∫æT QU·∫¢ EXTRACTION")
    print("=" * 80)
    print(f"‚úÖ Th√†nh c√¥ng: {success_count}/{len(files)} files")
    print(f"‚ùå Th·∫•t b·∫°i: {len(failed_files)} files")

    if failed_files:
        print("\nDanh s√°ch files th·∫•t b·∫°i:")
        for f in failed_files[:10]:  # Hi·ªÉn th·ªã max 10 files
            print(f"  - {f}")
        if len(failed_files) > 10:
            print(f"  ... v√† {len(failed_files) - 10} files kh√°c")

    print(f"\nüìä D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_dir}")
    print("=" * 80)


if __name__ == "__main__":
    main()
