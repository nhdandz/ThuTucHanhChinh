#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Query Enhancement - Stage 1 of Retrieval Pipeline
Uses Ollama LLM to enhance and expand queries
"""

import sys
import re
import json
import requests
from typing import List, Dict, Optional
from dataclasses import dataclass

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')


# Procedure code pattern (e.g., 1.013133, 2.002767, 3.000423)
PROCEDURE_CODE_PATTERN = r'\b\d+\.\d{5,6}\b'

# Intent mapping for query classification
INTENT_MAPPING = {
    "documents": ["gi·∫•y t·ªù c·∫ßn n·ªôp", "h·ªì s∆° bao g·ªìm", "vƒÉn b·∫£n n·ªôp", "t√†i li·ªáu c·∫ßn", "n·ªôp g√¨"],
    "requirements": ["ƒëi·ªÅu ki·ªán", "y√™u c·∫ßu", "ai ƒë∆∞·ª£c", "ƒë·ªëi t∆∞·ª£ng", "ƒë∆∞·ª£c l√†m", "ƒë∆∞·ª£c ph√©p"],
    "process": ["tr√¨nh t·ª±", "c√°c b∆∞·ªõc", "l√†m th·∫ø n√†o", "quy tr√¨nh", "c√°ch th·ª©c"],
    "legal": ["cƒÉn c·ª©", "ph√°p l√Ω", "lu·∫≠t", "ngh·ªã ƒë·ªãnh", "th√¥ng t∆∞", "quy ƒë·ªãnh"],
    "timeline": ["th·ªùi gian", "bao l√¢u", "th·ªùi h·∫°n", "m·∫•t bao l√¢u", "trong v√≤ng", "ng√†y l√†m vi·ªác"],
    "fees": ["ph√≠", "l·ªá ph√≠", "chi ph√≠", "t·ªën", "gi√°", "m·∫•t bao nhi√™u"],
    "location": ["·ªü ƒë√¢u", "ƒë·ªãa ch·ªâ", "n∆°i", "c∆° quan n√†o", "ƒë·∫øn ƒë√¢u"]
}

# Negative patterns - if these appear, disqualify the intent
# Used to handle compound queries where "h·ªì s∆°" appears but question is about timing/process
INTENT_EXCLUSIONS = {
    "documents": ["th·ªùi gian", "bao l√¢u", "th·ªùi h·∫°n", "h√¨nh th·ª©c th√¥ng b√°o", "th√¥ng b√°o"]
}


@dataclass
class QueryInfo:
    """Enhanced query information"""
    original_query: str
    intent: str
    query_variations: List[str]
    entities: Dict[str, str]
    filters: Dict[str, str]
    exact_code: Optional[str] = None  # Detected procedure code (e.g., "1.013133")


class OllamaQueryEnhancer:
    """
    Query enhancer using Ollama LLM
    Detects intent, extracts entities, generates query variations
    """

    def __init__(
        self,
        model_name: str = "qwen3:8b",
        ollama_url: str = "http://localhost:11434"
    ):
        """
        Initialize query enhancer

        Args:
            model_name: Ollama LLM model (e.g., "qwen3:8b", "mistral", "llama3.1")
            ollama_url: Ollama server URL
        """
        print(f"üîÑ Initializing Query Enhancer")
        print(f"   Model: {model_name}")
        print(f"   Server: {ollama_url}")

        self.model_name = model_name
        self.ollama_url = ollama_url
        self.generate_endpoint = f"{ollama_url}/api/generate"

        print(f"‚úÖ Query Enhancer initialized!")

    def _call_ollama(self, prompt: str, system: Optional[str] = None) -> str:
        """Call Ollama LLM API"""
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.3  # Low temperature for consistency
            }
        }

        if system:
            payload["system"] = system

        response = requests.post(
            self.generate_endpoint,
            json=payload,
            timeout=60
        )

        if response.status_code != 200:
            raise Exception(f"Ollama API error: {response.status_code}")

        return response.json()["response"].strip()

    def detect_intent(self, question: str) -> str:
        """
        Detect question intent using weighted keyword matching + LLM

        Args:
            question: User question

        Returns:
            Intent type (documents, requirements, process, etc.)
        """
        # Try multi-intent keyword scoring
        question_lower = question.lower()

        # Count matches for each intent
        intent_scores = {}
        for intent, keywords in INTENT_MAPPING.items():
            score = sum(1 for kw in keywords if kw in question_lower)

            # Apply exclusions - disqualify intent if exclusion keywords present
            if intent in INTENT_EXCLUSIONS:
                has_exclusion = any(excl in question_lower for excl in INTENT_EXCLUSIONS[intent])
                if has_exclusion:
                    score = 0  # Disqualify this intent

            if score > 0:
                intent_scores[intent] = score

        # Return intent with highest score
        if intent_scores:
            best_intent = max(intent_scores, key=intent_scores.get)
            return best_intent

        # If no keyword match, use LLM
        prompt = f"""C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{question}"

X√°c ƒë·ªãnh intent (m·ª•c ƒë√≠ch) c·ªßa c√¢u h·ªèi. Ch·ªçn M·ªòT trong c√°c intent sau:
- documents: H·ªèi v·ªÅ gi·∫•y t·ªù, h·ªì s∆° c·∫ßn n·ªôp
- requirements: H·ªèi v·ªÅ ƒëi·ªÅu ki·ªán, y√™u c·∫ßu, ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c l√†m
- process: H·ªèi v·ªÅ quy tr√¨nh, tr√¨nh t·ª±, c√°c b∆∞·ªõc th·ª±c hi·ªán
- legal: H·ªèi v·ªÅ cƒÉn c·ª© ph√°p l√Ω
- timeline: H·ªèi v·ªÅ th·ªùi gian, th·ªùi h·∫°n
- fees: H·ªèi v·ªÅ ph√≠, l·ªá ph√≠
- location: H·ªèi v·ªÅ ƒë·ªãa ch·ªâ, ƒë·ªãa ƒëi·ªÉm
- overview: H·ªèi t·ªïng quan v·ªÅ th·ªß t·ª•c

Ch·ªâ tr·∫£ v·ªÅ T√äN INTENT, kh√¥ng gi·∫£i th√≠ch.
Intent:"""

        try:
            intent = self._call_ollama(prompt).strip().lower()
            # Validate intent
            valid_intents = list(INTENT_MAPPING.keys()) + ["overview"]
            if intent in valid_intents:
                return intent
        except:
            pass

        # Default to overview
        return "overview"

    def extract_entities(self, question: str) -> Dict[str, str]:
        """
        Extract entities from question (procedure name, field, keywords)

        Args:
            question: User question

        Returns:
            Dictionary of extracted entities
        """
        prompt = f"""Tr√≠ch xu·∫•t th√¥ng tin t·ª´ c√¢u h·ªèi sau:
"{question}"

H√£y tr√≠ch xu·∫•t:
1. thu_tuc_name: T√™n th·ªß t·ª•c h√†nh ch√≠nh (n·∫øu c√≥)
2. linh_vuc: Lƒ©nh v·ª±c (VD: h·ªô t·ªãch, ƒëƒÉng k√Ω kinh doanh, x√¢y d·ª±ng...)
3. keywords: T·ª´ kh√≥a ch√≠nh

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
  "thu_tuc_name": "...",
  "linh_vuc": "...",
  "keywords": ["...", "..."]
}}

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch."""

        try:
            response = self._call_ollama(prompt)
            # Extract JSON from response
            start = response.find("{")
            end = response.rfind("}") + 1
            if start != -1 and end > start:
                entities = json.loads(response[start:end])
                return entities
        except:
            pass

        # Default empty entities
        return {"thu_tuc_name": "", "linh_vuc": "", "keywords": []}

    def generate_query_variations(self, question: str, intent: str, num_variations: int = 3) -> List[str]:
        """
        Generate query variations for multi-query retrieval

        Args:
            question: Original question
            intent: Detected intent
            num_variations: Number of variations to generate

        Returns:
            List of query variations
        """
        prompt = f"""C√¢u h·ªèi g·ªëc: "{question}"
Intent: {intent}

H√£y t·∫°o {num_variations} variations (c√°ch di·ªÖn ƒë·∫°t kh√°c) c·ªßa c√¢u h·ªèi n√†y ƒë·ªÉ t√¨m ki·∫øm hi·ªáu qu·∫£ h∆°n.

Y√™u c·∫ßu:
1. Gi·ªØ nguy√™n √Ω nghƒ©a c·ªßa c√¢u h·ªèi g·ªëc
2. S·ª≠ d·ª•ng t·ª´ ƒë·ªìng nghƒ©a
3. Thay ƒë·ªïi c·∫•u tr√∫c c√¢u
4. T·∫≠p trung v√†o intent "{intent}"

Tr·∫£ v·ªÅ JSON array:
["variation 1", "variation 2", "variation 3"]

Ch·ªâ tr·∫£ v·ªÅ JSON array, kh√¥ng gi·∫£i th√≠ch."""

        try:
            response = self._call_ollama(prompt)
            # Extract JSON array
            start = response.find("[")
            end = response.rfind("]") + 1
            if start != -1 and end > start:
                variations = json.loads(response[start:end])
                return variations[:num_variations]
        except:
            pass

        # Fallback: simple variations
        return [
            question,
            question.replace("c·∫ßn g√¨", "bao g·ªìm nh·ªØng g√¨"),
            question.replace("l√†m th·∫ø n√†o", "quy tr√¨nh")
        ][:num_variations]

    def _extract_procedure_code(self, question: str) -> Optional[str]:
        """
        Extract procedure code from query using regex pattern

        Args:
            question: User question

        Returns:
            Procedure code if found (e.g., "1.013133"), None otherwise
        """
        match = re.search(PROCEDURE_CODE_PATTERN, question)
        if match:
            return match.group(0)
        return None

    def _rewrite_query(self, question: str) -> str:
        """
        Rewrite complex queries into simplified form for better retrieval

        Removes filler words and question patterns, keeps domain-specific keywords

        Args:
            question: Original query

        Returns:
            Simplified query
        """
        # Filler words/patterns to remove
        filler_patterns = [
            r'^n·∫øu\s+(t√¥i|m√¨nh|em)\s+',  # "N·∫øu t√¥i/m√¨nh/em"
            r'\s+th√¨\s+',  # " th√¨ "
            r'\s+c√≥\s+',  # " c√≥ " (when not part of domain term)
            r'(kh√°c\s+g√¨|kh√°c\s+nhau\s+nh∆∞\s+th·∫ø\s+n√†o|s·ª±\s+kh√°c\s+bi·ªát)',  # Comparison phrases
            r'(so\s+v·ªõi|v·ªõi)',  # "so v·ªõi", "v·ªõi"
            r'(b·∫±ng\s+c√°ch\s+n√†o|nh∆∞\s+th·∫ø\s+n√†o)',  # How questions
            r'\?$',  # Question mark at end
        ]

        simplified = question.lower()

        # Remove filler patterns
        for pattern in filler_patterns:
            simplified = re.sub(pattern, ' ', simplified, flags=re.IGNORECASE)

        # Normalize spaces
        simplified = re.sub(r'\s+', ' ', simplified).strip()

        # If query became too short after cleaning, keep original
        if len(simplified.split()) < 3:
            return question

        return simplified

    def enhance_query(self, question: str) -> QueryInfo:
        """
        Main method: Enhance query with intent detection, entity extraction, variations

        Args:
            question: User question

        Returns:
            QueryInfo object with enhanced information
        """
        print(f"\nüîç Enhancing query: '{question}'")

        # Step 0: Extract exact procedure code (if present)
        exact_code = self._extract_procedure_code(question)
        if exact_code:
            print(f"   ‚úÖ Exact code detected: {exact_code}")

        # Step 0.5: Query rewriting for better retrieval
        rewritten_query = self._rewrite_query(question)
        if rewritten_query != question and rewritten_query.lower() != question.lower():
            print(f"   üîÑ Query rewritten: '{rewritten_query}'")
            # Use rewritten query for intent detection and variations
            query_for_processing = rewritten_query
        else:
            query_for_processing = question

        # Step 1: Detect intent (use original for better context)
        intent = self.detect_intent(question)
        print(f"   Intent: {intent}")

        # Step 2: Extract entities (use original for completeness)
        entities = self.extract_entities(question)
        print(f"   Entities: {entities}")

        # Step 3: Generate variations (include rewritten query as first variation)
        if query_for_processing != question:
            variations = [query_for_processing] + self.generate_query_variations(question, intent, num_variations=2)
        else:
            variations = self.generate_query_variations(question, intent, num_variations=3)
        print(f"   Variations: {len(variations)} generated")

        # Step 4: Build filters for vector search
        filters = {}
        if intent != "overview":
            # Map intent to chunk_type (can be single string or list of strings)
            intent_to_chunk_type = {
                "documents": "child_documents",
                "requirements": "child_requirements",
                "process": "child_process",
                "timeline": ["child_process", "child_fees_timing"],  # Timeline needs both process steps AND detailed timing info
                "legal": "child_legal"
            }
            if intent in intent_to_chunk_type:
                filters["chunk_type"] = intent_to_chunk_type[intent]

        query_info = QueryInfo(
            original_query=question,
            intent=intent,
            query_variations=variations,
            entities=entities,
            filters=filters,
            exact_code=exact_code
        )

        return query_info


def test_query_enhancer():
    """Test query enhancer"""
    print("=" * 80)
    print("TEST QUERY ENHANCER")
    print("=" * 80)

    enhancer = OllamaQueryEnhancer(model_name="qwen3:8b")

    test_queries = [
        "ƒêƒÉng k√Ω k·∫øt h√¥n c·∫ßn gi·∫•y t·ªù g√¨?",
        "Ai ƒë∆∞·ª£c ph√©p ƒëƒÉng k√Ω kinh doanh?",
        "Th·ªß t·ª•c xin gi·∫•y ph√©p x√¢y d·ª±ng m·∫•t bao l√¢u?",
        "CƒÉn c·ª© ph√°p l√Ω c·ªßa th·ªß t·ª•c ƒëƒÉng k√Ω h·ªô t·ªãch l√† g√¨?"
    ]

    for query in test_queries:
        print()
        result = enhancer.enhance_query(query)
        print(f"   Filters: {result.filters}")
        print()

    print("=" * 80)


if __name__ == "__main__":
    test_query_enhancer()
