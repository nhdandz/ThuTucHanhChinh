# ðŸ›ï¸ Há»† THá»NG Há»ŽI ÄÃP THá»¦ Tá»¤C HÃ€NH CHÃNH - RAG SYSTEM

Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) cho 207 thá»§ tá»¥c hÃ nh chÃ­nh, tá»‘i Æ°u hÃ³a cho Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t.

## ðŸ“‹ Má»¤C Lá»¤C

- [Tá»•ng Quan](#tá»•ng-quan)
- [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [Cáº¥u TrÃºc Dá»± Ãn](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [Káº¿t Quáº£ Äáº¡t ÄÆ°á»£c](#káº¿t-quáº£-Ä‘áº¡t-Ä‘Æ°á»£c)
- [Roadmap Triá»ƒn Khai](#roadmap-triá»ƒn-khai)
- [Chiáº¿n LÆ°á»£c Ká»¹ Thuáº­t](#chiáº¿n-lÆ°á»£c-ká»¹-thuáº­t)
- [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [TÃ i Liá»‡u Tham Kháº£o](#tÃ i-liá»‡u-tham-kháº£o)

---

## ðŸŽ¯ Tá»”NG QUAN

### Má»¥c TiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng há»i Ä‘Ã¡p tá»± Ä‘á»™ng vá» thá»§ tá»¥c hÃ nh chÃ­nh vá»›i **Ä‘á»™ chÃ­nh xÃ¡c > 95%**, giÃºp ngÆ°á»i dÃ¢n tra cá»©u nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c cÃ¡c thÃ´ng tin vá»:
- Giáº¥y tá» cáº§n thiáº¿t
- YÃªu cáº§u vÃ  Ä‘iá»u kiá»‡n
- Quy trÃ¬nh thá»±c hiá»‡n
- CÄƒn cá»© phÃ¡p lÃ½
- Thá»i gian vÃ  chi phÃ­

### Äáº·c Äiá»ƒm Ná»•i Báº­t

âœ… **Accuracy-First**: Tá»‘i Æ°u hÃ³a Ä‘á»™ chÃ­nh xÃ¡c thay vÃ¬ tá»‘c Ä‘á»™
âœ… **Hierarchical Chunking**: 2-tier structure (Parent + Child chunks)
âœ… **5-Stage Retrieval**: Pipeline retrieval nÃ¢ng cao vá»›i multi-query fusion vÃ  re-ranking
âœ… **Multi-Layer Validation**: 5 layers kiá»ƒm tra Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i
âœ… **BGE-M3 Embeddings**: Model embedding Ä‘a ngÃ´n ngá»¯ tá»‘i Æ°u cho tiáº¿ng Viá»‡t (1024-dim)
âœ… **Hybrid Output**: Káº¿t há»£p JSON (structured) vÃ  Natural Language

---

## ðŸ—ï¸ KIáº¾N TRÃšC Há»† THá»NG

### Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Embedding** | BGE-M3 (BAAI/bge-m3) | Vector embeddings 1024-dim |
| **Vector DB** | Qdrant / ChromaDB | LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m vector |
| **Reranker** | BAAI/bge-reranker-v2-m3 | Cross-encoder reranking |
| **LLM** | qwen3-8b (OpenAI API) | Generation & synthesis |
| **NLI** | xlm-roberta-large-xnli | Hallucination detection |
| **Chunking** | Tiktoken (cl100k_base) | Token counting |

### Kiáº¿n TrÃºc RAG Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       USER QUERY                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: QUERY ENHANCEMENT                                       â”‚
â”‚  â€¢ Intent Detection (documents/requirements/process/legal)       â”‚
â”‚  â€¢ Query Expansion                                               â”‚
â”‚  â€¢ Multi-Query Generation (N=3)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: HIERARCHICAL RETRIEVAL                                  â”‚
â”‚  â€¢ Step 1: Retrieve Parent chunks (K=5)                          â”‚
â”‚  â€¢ Step 2: Retrieve Child chunks for each parent (K=3)           â”‚
â”‚  â€¢ Total: 5 parent + 15 child = 20 chunks                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3: MULTI-QUERY FUSION                                      â”‚
â”‚  â€¢ Reciprocal Rank Fusion (RRF)                                  â”‚
â”‚  â€¢ Combine results from 3 queries                                â”‚
â”‚  â€¢ Top-K=10 final chunks                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 4: CROSS-ENCODER RE-RANKING                                â”‚
â”‚  â€¢ BGE Reranker v2-m3                                            â”‚
â”‚  â€¢ Re-score 10 chunks                                            â”‚
â”‚  â€¢ Select top-5 most relevant                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 5: CONTEXT ASSEMBLY                                        â”‚
â”‚  â€¢ Context window management (~3500 tokens)                      â”‚
â”‚  â€¢ Chunk priority ordering                                       â”‚
â”‚  â€¢ Metadata enrichment                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GENERATION & ANSWER SYNTHESIS                                    â”‚
â”‚  â€¢ qwen3-8b with structured prompt                                  â”‚
â”‚  â€¢ Hybrid output: JSON + Natural Language                        â”‚
â”‚  â€¢ Citation with chunk references                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MULTI-LAYER VALIDATION                                           â”‚
â”‚  Layer 1: NLI Hallucination Detection                            â”‚
â”‚  Layer 2: Completeness Check                                     â”‚
â”‚  Layer 3: Cross-Reference Validation                             â”‚
â”‚  Layer 4: Self-Consistency (N=5 samples)                         â”‚
â”‚  Layer 5: Chain-of-Verification (CoVe)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                       FINAL ANSWER
```

---

## ðŸ“ Cáº¤U TRÃšC Dá»° ÃN

```
thu_tuc_rag/
â”‚
â”œâ”€â”€ README.md                          # File nÃ y
â”œâ”€â”€ requirements.txt                   # Dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # 207 .doc files gá»‘c
â”‚   â”‚   â””â”€â”€ ChiTietTTHC_*.doc
â”‚   â”‚
â”‚   â”œâ”€â”€ extracted/                    # 207 JSON files Ä‘Ã£ extract
â”‚   â”‚   â”œâ”€â”€ 1.013124.json
â”‚   â”‚   â”œâ”€â”€ 1.013125.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ chunks/                       # Chunks data
â”‚   â”‚   â”œâ”€â”€ all_chunks.json          # 1,084 chunks
â”‚   â”‚   â””â”€â”€ chunking_stats.json      # Statistics
â”‚   â”‚
â”‚   â””â”€â”€ embeddings/                   # Vector embeddings (Phase 3)
â”‚       â””â”€â”€ chunks_with_embeddings.json
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extraction/                   # Phase 1: Data Extraction
â”‚   â”‚   â”œâ”€â”€ extract_documents.py     # Extract from .doc files
â”‚   â”‚   â””â”€â”€ data_validator.py        # Validate extracted data
â”‚   â”‚
â”‚   â”œâ”€â”€ chunking/                     # Phase 2: Chunking
â”‚   â”‚   â”œâ”€â”€ hierarchical_chunker.py  # 2-tier chunking logic
â”‚   â”‚   â””â”€â”€ test_chunker.py          # Testing
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/                    # Phase 3: Retrieval Pipeline
â”‚   â”‚   â”œâ”€â”€ embedding_generator.py   # BGE-M3 embeddings
â”‚   â”‚   â”œâ”€â”€ vector_store.py          # Qdrant setup
â”‚   â”‚   â”œâ”€â”€ query_processor.py       # Query enhancement
â”‚   â”‚   â””â”€â”€ retrieval_pipeline.py    # 5-stage retrieval
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/                   # Phase 4: Generation
â”‚   â”‚   â”œâ”€â”€ answer_generator.py      # qwen3-8b integration
â”‚   â”‚   â””â”€â”€ prompt_templates.py      # Prompt engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ validation/                   # Phase 5: Validation
â”‚   â”‚   â”œâ”€â”€ nli_validator.py         # Hallucination detection
â”‚   â”‚   â”œâ”€â”€ consistency_checker.py   # Self-consistency
â”‚   â”‚   â””â”€â”€ cove_verifier.py         # Chain-of-Verification
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/                   # Phase 6: Testing
â”‚       â”œâ”€â”€ test_dataset.py          # 50-100 Q&A pairs
â”‚       â””â”€â”€ metrics.py               # Accuracy, precision, recall
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                   # Configuration
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ analysis.ipynb                # Data analysis
```

---

## âœ… Káº¾T QUáº¢ Äáº T ÄÆ¯á»¢C

### Phase 1: Data Extraction âœ… HOÃ€N THÃ€NH

**Káº¿t quáº£:**
- âœ… Extract thÃ nh cÃ´ng **207/207 files** (100% success rate)
- âœ… 20 fields/thá»§ tá»¥c vá»›i cáº¥u trÃºc Ä‘á»“ng nháº¥t
- âœ… 3 báº£ng dá»¯ liá»‡u: ThÃ nh pháº§n há»“ sÆ¡, CÄƒn cá»© phÃ¡p lÃ½, HÃ¬nh thá»©c ná»™p

**Files táº¡o ra:**
- `extract_documents.py` - Script extraction chÃ­nh
- `data_validator.py` - Multi-layer validation
- 207 JSON files trong `data/extracted/`

**Cáº¥u trÃºc JSON:**
```json
{
  "thu_tuc_id": "1.013124",
  "source_file": "ChiTietTTHC_1.013124.doc",
  "metadata": {
    "mÃ£_thá»§_tá»¥c": "...",
    "tÃªn_thá»§_tá»¥c": "...",
    "lÄ©nh_vá»±c": "...",
    "cáº¥p_thá»±c_hiá»‡n": "...",
    "loáº¡i_thá»§_tá»¥c": "..."
  },
  "content": {
    "Ä‘á»‘i_tÆ°á»£ng_thá»±c_hiá»‡n": "...",
    "yÃªu_cáº§u_Ä‘iá»u_kiá»‡n_thá»±c_hiá»‡n": "...",
    "trÃ¬nh_tá»±_thá»±c_hiá»‡n": "...",
    "cÃ¡ch_thá»©c_thá»±c_hiá»‡n": "...",
    "cÆ¡_quan_thá»±c_hiá»‡n": "...",
    "káº¿t_quáº£_thá»±c_hiá»‡n": "..."
  },
  "tables": {
    "thanh_phan_ho_so": [...],
    "can_cu_phap_ly": [...],
    "hinh_thuc_nop": [...]
  }
}
```

---

### Phase 2: Hierarchical Chunking âœ… HOÃ€N THÃ€NH

**Káº¿t quáº£:**
- âœ… **1,084 chunks** tá»•ng cá»™ng
- âœ… **207 Parent chunks** (overview/routing)
- âœ… **877 Child chunks** (detailed info)

**PhÃ¢n bá»‘ Child Chunks:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk Type         â”‚ Count  â”‚ Avg Tkns â”‚ Max Tkns â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parent Overview    â”‚   207  â”‚    353   â”‚    601   â”‚
â”‚ Child Documents    â”‚   236  â”‚    640   â”‚   2114   â”‚
â”‚ Child Requirements â”‚   300  â”‚    484   â”‚    769   â”‚
â”‚ Child Process      â”‚   118  â”‚    698   â”‚    896   â”‚
â”‚ Child Legal        â”‚   223  â”‚    350   â”‚    930   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Chiáº¿n lÆ°á»£c Chunking:**

**TIER 1: Parent Chunks (Overview)**
- Má»¥c Ä‘Ã­ch: Quick answer + Routing to children
- Ná»™i dung: TÃ³m táº¯t thá»§ tá»¥c, Ä‘á»‘i tÆ°á»£ng, cÆ¡ quan, thá»i gian, chi phÃ­
- Size: ~350 tokens
- LuÃ´n Ä‘Æ°á»£c retrieve trÆ°á»›c

**TIER 2: Child Chunks (Detailed)**

| Type | Content | Max Tokens | Overlap |
|------|---------|------------|---------|
| **Child A - Documents** | Danh sÃ¡ch giáº¥y tá» + CÃ¡ch ná»™p | 1024 | 100 |
| **Child B - Requirements** | Äá»‘i tÆ°á»£ng + Äiá»u kiá»‡n | 768 | 200 |
| **Child C - Process** | TrÃ¬nh tá»± + Quy trÃ¬nh | 896 | 150 |
| **Child D - Legal** | CÄƒn cá»© phÃ¡p lÃ½ | 512 | 50 |

**Äáº·c Ä‘iá»ƒm:**
- Má»—i child chunk cÃ³ **Parent Context** á»Ÿ Ä‘áº§u
- Preserve structure (numbered lists, tables)
- Overlap Ä‘á»ƒ trÃ¡nh máº¥t ngá»¯ cáº£nh

**Files táº¡o ra:**
- `hierarchical_chunker.py` - Core chunking logic
- `test_chunker.py` - Testing script
- `all_chunks.json` - 1,084 chunks
- `chunking_stats.json` - Statistics

---

### Phase 3: Retrieval Pipeline ðŸ”„ ÄANG TRIá»‚N KHAI

**Má»¥c tiÃªu:**
- [ ] Setup BGE-M3 embedding model
- [ ] Generate embeddings cho 1,084 chunks
- [ ] Setup Qdrant vector database
- [ ] Implement query processor
- [ ] Implement 5-stage retrieval pipeline
- [ ] Test vá»›i sample queries

**5-Stage Retrieval Strategy:**

**Stage 1: Query Enhancement**
```python
Input: "Thá»§ tá»¥c cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng cáº§n giáº¥y tá» gÃ¬?"

Processing:
1. Intent Detection â†’ "documents" (tÃ¬m giáº¥y tá»)
2. Query Expansion â†’ Add synonyms, related terms
3. Multi-Query Generation:
   - Q1: "ThÃ nh pháº§n há»“ sÆ¡ cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng"
   - Q2: "Giáº¥y tá» cáº§n thiáº¿t xÃ¢y dá»±ng"
   - Q3: "Documents required for construction permit"
```

**Stage 2: Hierarchical Retrieval**
```
Step 1: Retrieve Parent chunks (K=5)
  â†’ Get top-5 most relevant procedures

Step 2: For each parent, retrieve Child chunks (K=3)
  â†’ Based on intent, retrieve from specific child type
  â†’ 5 parents Ã— 3 children = 15 child chunks

Total: 5 parent + 15 child = 20 chunks
```

**Stage 3: Multi-Query Fusion (RRF)**
```python
# Reciprocal Rank Fusion
for each chunk in results:
    RRF_score = Î£(1 / (k + rank_i))  # k=60

Sort by RRF_score â†’ Top-10 chunks
```

**Stage 4: Cross-Encoder Re-Ranking**
```python
# BGE Reranker v2-m3
scores = reranker.compute_score([
    [query, chunk_1],
    [query, chunk_2],
    ...
])

Sort by scores â†’ Top-5 chunks
```

**Stage 5: Context Assembly**
```python
# Build context vá»›i priority
Context window: ~3500 tokens

Priority order:
1. Parent chunks cá»§a thá»§ tá»¥c matching
2. Child chunks theo intent type
3. Related chunks náº¿u cÃ²n chá»—

Format: [PARENT CONTEXT] + [MAIN CONTENT] + [METADATA]
```

---

### Phase 4: Generation & Answer Synthesis ðŸ“‹ Káº¾ HOáº CH

**LLM:** qwen3-8b (ollama da tai)

**Prompt Engineering:**
```
System: Báº¡n lÃ  trá»£ lÃ½ thá»§ tá»¥c hÃ nh chÃ­nh. Tráº£ lá»i chÃ­nh xÃ¡c dá»±a trÃªn context.

Context: [5 chunks Ä‘Ã£ rerank]

User Query: {query}

Instructions:
1. Tráº£ lá»i chÃ­nh xÃ¡c dá»±a 100% vÃ o context
2. Format: JSON + Natural Language
3. Cite sources vá»›i chunk_id
4. Náº¿u khÃ´ng cÃ³ thÃ´ng tin â†’ nÃ³i rÃµ "KhÃ´ng cÃ³ thÃ´ng tin"
5. KHÃ”NG tá»± bá»‹a thÃªm

Output Format:
{
  "answer": "...",
  "thu_tuc": {
    "ma": "...",
    "ten": "..."
  },
  "documents": [...],
  "sources": ["chunk_id_1", "chunk_id_2"]
}
```

**Output Format - Hybrid:**

**JSON (Structured):**
```json
{
  "answer": "Äá»ƒ cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng, báº¡n cáº§n ná»™p 5 loáº¡i giáº¥y tá»...",
  "thu_tuc": {
    "ma": "1.013124",
    "ten": "Thá»§ tá»¥c cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng"
  },
  "documents": [
    {
      "name": "ÄÆ¡n Ä‘á» nghá»‹ cáº¥p phÃ©p",
      "quantity": "Báº£n chÃ­nh: 1",
      "note": ""
    },
    ...
  ],
  "thoi_han": "30 ngÃ y lÃ m viá»‡c",
  "phi_le_phi": "PhÃ­: 0 Ä‘á»“ng",
  "sources": ["1.013124_child_documents_0", "1.013124_parent_overview"]
}
```

**Natural Language:**
```
Äá»ƒ lÃ m thá»§ tá»¥c cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng (MÃ£: 1.013124), báº¡n cáº§n ná»™p cÃ¡c giáº¥y tá» sau:

1. ÄÆ¡n Ä‘á» nghá»‹ cáº¥p phÃ©p (Báº£n chÃ­nh: 1)
2. Báº£n váº½ thiáº¿t káº¿ ká»¹ thuáº­t (Báº£n chÃ­nh: 1)
...

Thá»i gian giáº£i quyáº¿t: 30 ngÃ y lÃ m viá»‡c
PhÃ­, lá»‡ phÃ­: PhÃ­ 0 Ä‘á»“ng

Ná»™p há»“ sÆ¡ táº¡i: [Ä‘á»‹a chá»‰]

[Sources: Chunk 1.013124_child_documents_0, 1.013124_parent_overview]
```

---

### Phase 5: Optimization & Validation ðŸ“‹ Káº¾ HOáº CH

**Multi-Layer Validation Framework:**

**Layer 1: NLI Hallucination Detection**
```python
Model: xlm-roberta-large-xnli

For each sentence in answer:
    NLI_score = model(premise=context, hypothesis=sentence)

    If NLI_score["contradiction"] > 0.5:
        â†’ Flag as hallucination
        â†’ Request regeneration or remove sentence
```

**Layer 2: Completeness Check**
```python
# Check if answer addresses all parts of query
query_aspects = extract_aspects(query)
answer_aspects = extract_aspects(answer)

completeness = len(answer_aspects âˆ© query_aspects) / len(query_aspects)

If completeness < 0.8:
    â†’ Request more information retrieval
```

**Layer 3: Cross-Reference Validation**
```python
# Verify facts across multiple chunks
For each fact in answer:
    supporting_chunks = count_supporting_evidence(fact, chunks)

    If supporting_chunks < 2:
        â†’ Flag as low confidence
        â†’ Add uncertainty marker
```

**Layer 4: Self-Consistency (Majority Voting)**
```python
# Generate N=5 answers independently
answers = []
for i in range(5):
    answer_i = generate_answer(query, context, temperature=0.7)
    answers.append(answer_i)

# Extract key facts from each
facts_matrix = extract_facts(answers)  # 5 Ã— M matrix

# Majority voting
final_facts = []
for fact in facts_matrix:
    if count(fact) >= 3:  # 60% agreement
        final_facts.append(fact)

final_answer = synthesize(final_facts)
```

**Layer 5: Chain-of-Verification (CoVe)**
```python
# Step 1: Generate initial answer
baseline_answer = generate_answer(query, context)

# Step 2: LLM plans verification questions
verification_questions = llm_generate_questions(baseline_answer)
# Example: "CÃ³ chÃ­nh xÃ¡c lÃ  cáº§n 5 giáº¥y tá» khÃ´ng?"
#          "Thá»i háº¡n 30 ngÃ y cÃ³ Ä‘Ãºng khÃ´ng?"

# Step 3: Answer verification questions
verifications = []
for q in verification_questions:
    v = generate_answer(q, context)
    verifications.append(v)

# Step 4: Generate final verified answer
final_answer = generate_answer_with_verifications(
    query, context, baseline_answer, verifications
)
```

---

### Phase 6: Evaluation & Testing ðŸ“‹ Káº¾ HOáº CH

**Test Dataset:**
- 50-100 cáº·p (Question, Ground Truth Answer)
- Cover táº¥t cáº£ loáº¡i query:
  - Documents queries (30%)
  - Requirements queries (25%)
  - Process queries (25%)
  - Legal queries (10%)
  - Mixed queries (10%)

**Evaluation Metrics:**

| Metric | Target | Method |
|--------|--------|--------|
| **Accuracy** | > 95% | Exact + Semantic match |
| **Precision** | > 90% | Correct facts / Total facts |
| **Recall** | > 90% | Retrieved facts / Total facts |
| **F1-Score** | > 90% | Harmonic mean |
| **Hallucination Rate** | < 5% | NLI detection |
| **Latency** | 3-5s | End-to-end |

**Test Categories:**

```python
# 1. Factual Accuracy
"Thá»§ tá»¥c X cáº§n bao nhiÃªu giáº¥y tá»?"
â†’ Check exact number match

# 2. Completeness
"Quy trÃ¬nh lÃ m thá»§ tá»¥c Y nhÆ° tháº¿ nÃ o?"
â†’ Check all steps present

# 3. Consistency
"Thá»i gian giáº£i quyáº¿t thá»§ tá»¥c Z?"
â†’ Check no conflicting info

# 4. Citation Quality
â†’ Check all facts have source chunks

# 5. Edge Cases
"Thá»§ tá»¥c khÃ´ng tá»“n táº¡i"
â†’ Should return "KhÃ´ng tÃ¬m tháº¥y"
```

---

## ðŸ—ºï¸ ROADMAP TRIá»‚N KHAI

### Timeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase       â”‚ Tasks                                â”‚ Status   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 1     â”‚ Data Extraction                      â”‚ âœ… DONE  â”‚
â”‚             â”‚ - Extract 207 .doc files             â”‚          â”‚
â”‚             â”‚ - Validate data                      â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 2     â”‚ Chunking & Indexing                  â”‚ âœ… DONE  â”‚
â”‚             â”‚ - Hierarchical chunker               â”‚          â”‚
â”‚             â”‚ - Generate 1,084 chunks              â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 3     â”‚ Retrieval Pipeline                   â”‚ ðŸ”„ IN PROGRESSâ”‚
â”‚             â”‚ - BGE-M3 embeddings                  â”‚          â”‚
â”‚             â”‚ - Qdrant vector DB                   â”‚          â”‚
â”‚             â”‚ - 5-stage retrieval                  â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 4     â”‚ Generation & Synthesis               â”‚ ðŸ“‹ PLANNEDâ”‚
â”‚             â”‚ - qwen3-8b integration                  â”‚          â”‚
â”‚             â”‚ - Prompt engineering                 â”‚          â”‚
â”‚             â”‚ - Hybrid output format               â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 5     â”‚ Optimization & Validation            â”‚ ðŸ“‹ PLANNEDâ”‚
â”‚             â”‚ - NLI hallucination detection        â”‚          â”‚
â”‚             â”‚ - Self-consistency                   â”‚          â”‚
â”‚             â”‚ - Chain-of-Verification              â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 6     â”‚ Evaluation & Testing                 â”‚ ðŸ“‹ PLANNEDâ”‚
â”‚             â”‚ - Create test dataset                â”‚          â”‚
â”‚             â”‚ - Measure metrics                    â”‚          â”‚
â”‚             â”‚ - Optimize performance               â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ“ CHIáº¾N LÆ¯á»¢C Ká»¸ THUáº¬T

### 1. Hierarchical Chunking Strategy

**Táº¡i sao 2-tier?**
- **Tier 1 (Parent)**: Fast routing, quick overview
  - User cÃ³ thá»ƒ Ä‘Æ°á»£c answer ngay tá»« parent
  - Hoáº·c parent giÃºp identify Ä‘Ãºng thá»§ tá»¥c

- **Tier 2 (Child)**: Detailed information
  - Chá»‰ retrieve children khi cáº§n details
  - TrÃ¡nh information overload

**Æ¯u Ä‘iá»ƒm:**
âœ… Reduce noise: KhÃ´ng retrieve táº¥t cáº£ details ngay tá»« Ä‘áº§u
âœ… Better precision: Parent lÃ m filter Ä‘áº§u tiÃªn
âœ… Scalable: Dá»… má»Ÿ rá»™ng khi thÃªm thá»§ tá»¥c
âœ… Context-aware: Child chunks cÃ³ parent context

### 2. Multi-Query Fusion (RRF)

**Táº¡i sao cáº§n 3 queries?**
- User query cÃ³ thá»ƒ diá»…n Ä‘áº¡t nhiá»u cÃ¡ch
- Má»™t query cÃ³ thá»ƒ miss relevant chunks
- 3 queries cover nhiá»u gÃ³c Ä‘á»™ hÆ¡n

**Reciprocal Rank Fusion:**
```
RRF(d) = Î£(1 / (k + rank_i(d)))

k = 60 (constant)
rank_i(d) = vá»‹ trÃ­ cá»§a document d trong query i
```

**Æ¯u Ä‘iá»ƒm:**
âœ… KhÃ´ng cáº§n normalize scores tá»« cÃ¡c models khÃ¡c nhau
âœ… Robust vá»›i outliers
âœ… Proven effectiveness (used by search engines)

### 3. Cross-Encoder Re-Ranking

**Táº¡i sao cáº§n reranking?**
- Bi-encoder (BGE-M3) fast nhÆ°ng less accurate
- Cross-encoder slow nhÆ°ng very accurate
- Strategy: Bi-encoder retrieve nhiá»u (K=10), Cross-encoder refine (K=5)

**BGE Reranker v2-m3:**
- Multilingual (support Vietnamese)
- Fine-tuned for relevance scoring
- Input: (query, document) pair â†’ score

### 4. Self-Consistency Voting

**Concept:**
Generate N=5 cÃ¢u tráº£ lá»i Ä‘á»™c láº­p â†’ Majority voting

**Táº¡i sao effective?**
- Reduce randomness cá»§a LLM
- Facts xuáº¥t hiá»‡n á»Ÿ nhiá»u answers â†’ high confidence
- Facts chá»‰ á»Ÿ 1-2 answers â†’ low confidence, cÃ³ thá»ƒ bá»

**Implementation:**
```python
answers = [generate(query, temp=0.7) for _ in range(5)]
facts = extract_facts(answers)  # Extract key facts
consensus = [f for f in facts if count(f) >= 3]  # 60% threshold
```

### 5. Chain-of-Verification (CoVe)

**4-Step Process:**
1. **Generate baseline answer**
2. **LLM self-generates verification questions**
   - "CÃ³ Ä‘Ãºng lÃ  cáº§n 5 giáº¥y tá»?"
   - "Thá»i háº¡n cÃ³ pháº£i 30 ngÃ y?"
3. **Answer verification questions independently**
4. **Revise answer based on verifications**

**Æ¯u Ä‘iá»ƒm:**
âœ… LLM tá»± detect vÃ  fix hallucinations
âœ… KhÃ´ng cáº§n external fact-checking DB
âœ… Proven to reduce hallucination rate by 20-40%

---

## ðŸš€ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### Installation

```bash
# Clone repository
cd thu_tuc_rag

# Install dependencies
pip install -r requirements.txt

# TÃ¹y chá»n: Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### Phase 1: Data Extraction

```bash
cd src/extraction
python extract_documents.py

# Output:
# - data/extracted/*.json (207 files)
```

### Phase 2: Chunking

```bash
cd src/chunking

# Test vá»›i vÃ i files
python test_chunker.py

# Chunk táº¥t cáº£
python hierarchical_chunker.py

# Output:
# - data/chunks/all_chunks.json
# - data/chunks/chunking_stats.json
```

### Phase 3: Generate Embeddings (In Progress)

```bash
cd src/retrieval
python embedding_generator.py

# Output:
# - data/embeddings/chunks_with_embeddings.json
```

### Phase 4: Setup Vector Database (Upcoming)

```bash
cd src/retrieval
python vector_store.py

# Khá»Ÿi Ä‘á»™ng Qdrant
docker run -p 6333:6333 qdrant/qdrant
```

### Phase 5: Run Query (Upcoming)

```bash
python main.py --query "Thá»§ tá»¥c cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng cáº§n giáº¥y tá» gÃ¬?"

# Output: JSON + Natural Language answer
```

---

## ðŸ“Š Dá»® LIá»†U THá»NG KÃŠ

### Extracted Data (Phase 1)

- **Tá»•ng sá»‘ thá»§ tá»¥c**: 207
- **ThÃ nh cÃ´ng**: 207/207 (100%)
- **TrÆ°á»ng dá»¯ liá»‡u**: 20 fields/thá»§ tá»¥c
- **Báº£ng**: 3 tables/thá»§ tá»¥c

**Field Length Statistics:**
```
YÃªu cáº§u Ä‘iá»u kiá»‡n: avg 834 chars, max 9,285 chars
ThÃ nh pháº§n há»“ sÆ¡: avg 709 chars, max 7,130 chars
TrÃ¬nh tá»± thá»±c hiá»‡n: 130/207 files missing (63%)
```

### Chunks Data (Phase 2)

**Overview:**
- **Total chunks**: 1,084
- **Parent chunks**: 207
- **Child chunks**: 877
- **Avg tokens/chunk**: 489
- **Procedures vá»›i Process chunks**: 118/207 (57%)

**Distribution:**
```
Parent Overview:    207 chunks (353 tokens avg)
Child Documents:    236 chunks (640 tokens avg)
Child Requirements: 300 chunks (484 tokens avg)
Child Process:      118 chunks (698 tokens avg)
Child Legal:        223 chunks (350 tokens avg)
```

---

## ðŸ”§ CONFIGURATION

### config/config.yaml

```yaml
# Embedding
embedding:
  model: "BAAI/bge-m3"
  dimension: 1024
  batch_size: 32

# Vector Database
vector_db:
  type: "qdrant"
  host: "localhost"
  port: 6333
  collection: "thu_tuc_chunks"

# Retrieval
retrieval:
  parent_top_k: 5
  child_top_k: 3
  rerank_top_k: 5
  multi_query_count: 3
  rrf_k: 60

# Generation
generation:
  model: "qwen3-8b"
  temperature: 0.1
  max_tokens: 1000

# Validation
validation:
  nli_threshold: 0.5
  consistency_samples: 5
  consistency_threshold: 0.6
  cove_enabled: true
```

---

## ðŸ“ˆ EXPECTED PERFORMANCE

### Target Metrics

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Accuracy** | > 95% | Administrative procedures require high precision |
| **Precision** | > 90% | Minimize false information |
| **Recall** | > 90% | Don't miss important information |
| **Hallucination Rate** | < 5% | Critical for legal documents |
| **Latency** | 3-5s | Acceptable for accuracy-first approach |

### Performance Optimizations

**Speed-Accuracy Tradeoffs:**
- âœ… Accept 3-5s latency for >95% accuracy
- âœ… Multi-query fusion â†’ Better recall
- âœ… Cross-encoder reranking â†’ Better precision
- âœ… Self-consistency â†’ Lower hallucination

**Potential Bottlenecks:**
- Embedding generation: ~30s for 1,084 chunks (one-time)
- Vector search: <100ms (Qdrant optimized)
- Cross-encoder reranking: ~500ms for 10 chunks
- LLM generation: ~2s (qwen3-8b)
- Validation (CoVe): +1-2s

**Total latency**: ~3-5s âœ…

---

## ðŸ§ª TESTING STRATEGY

### Test Dataset Structure

```python
{
  "id": "test_001",
  "category": "documents",  # documents/requirements/process/legal/mixed
  "query": "Thá»§ tá»¥c cáº¥p giáº¥y phÃ©p xÃ¢y dá»±ng cáº§n giáº¥y tá» gÃ¬?",
  "thu_tuc_id": "1.013124",
  "ground_truth": {
    "answer": "Cáº§n 5 loáº¡i giáº¥y tá»...",
    "documents": [...],
    "sources": ["1.013124_child_documents_0"]
  }
}
```

### Test Categories Distribution

```
Documents queries:     30 tests (30%)
Requirements queries:  25 tests (25%)
Process queries:       25 tests (25%)
Legal queries:         10 tests (10%)
Mixed queries:         10 tests (10%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                100 tests
```

### Evaluation Process

```python
for test in test_dataset:
    # Generate answer
    answer = rag_system.query(test["query"])

    # Evaluate
    accuracy = check_accuracy(answer, test["ground_truth"])
    precision = check_precision(answer, test["ground_truth"])
    recall = check_recall(answer, test["ground_truth"])
    hallucination = check_hallucination(answer, retrieved_chunks)

    # Record metrics
    metrics.append({
        "test_id": test["id"],
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "hallucination": hallucination
    })

# Aggregate
overall_accuracy = mean(metrics["accuracy"])
print(f"Overall Accuracy: {overall_accuracy:.2%}")
```
